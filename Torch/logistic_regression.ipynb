{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例1 MNIST-手写数字识别系统\n",
    "+ 算法思路\n",
    "    > 准备训练参数\n",
    "\n",
    "    > 准备数据集(训练集和测试集)\n",
    "\n",
    "    > 建立神经网络模型\n",
    "\n",
    "    > 选择优化算法, 计算 loss\n",
    "    \n",
    "    > 训练集上训练模型\n",
    "    \n",
    "    > 测试集上检验正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块导入\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 输入\n",
    "num_classes = 10\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "\n",
    "# train_dataset\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                          train=True,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "# test_dataset\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader (input pipeline)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,   # 导出图片数据集\n",
    "                                           batch_size=batch_size,   # 训练选取多少张图片\n",
    "                                           shuffle=True)            # 采取多少个子进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model 逻辑回归模型\n",
    "\n",
    "model = nn.Linear(input_size,num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes sfotmax internally\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/600], Loss: 0.9666\n",
      "Epoch [1/50], Step [200/600], Loss: 0.9651\n",
      "Epoch [1/50], Step [300/600], Loss: 0.9637\n",
      "Epoch [1/50], Step [400/600], Loss: 0.9595\n",
      "Epoch [1/50], Step [500/600], Loss: 0.9133\n",
      "Epoch [1/50], Step [600/600], Loss: 0.9581\n",
      "Epoch [2/50], Step [100/600], Loss: 0.9151\n",
      "Epoch [2/50], Step [200/600], Loss: 0.9136\n",
      "Epoch [2/50], Step [300/600], Loss: 0.8926\n",
      "Epoch [2/50], Step [400/600], Loss: 0.7798\n",
      "Epoch [2/50], Step [500/600], Loss: 0.8899\n",
      "Epoch [2/50], Step [600/600], Loss: 0.9163\n",
      "Epoch [3/50], Step [100/600], Loss: 0.8883\n",
      "Epoch [3/50], Step [200/600], Loss: 0.8564\n",
      "Epoch [3/50], Step [300/600], Loss: 0.8563\n",
      "Epoch [3/50], Step [400/600], Loss: 0.8123\n",
      "Epoch [3/50], Step [500/600], Loss: 0.6957\n",
      "Epoch [3/50], Step [600/600], Loss: 0.7331\n",
      "Epoch [4/50], Step [100/600], Loss: 0.7424\n",
      "Epoch [4/50], Step [200/600], Loss: 0.7607\n",
      "Epoch [4/50], Step [300/600], Loss: 0.7203\n",
      "Epoch [4/50], Step [400/600], Loss: 0.7716\n",
      "Epoch [4/50], Step [500/600], Loss: 0.7080\n",
      "Epoch [4/50], Step [600/600], Loss: 0.8275\n",
      "Epoch [5/50], Step [100/600], Loss: 0.6892\n",
      "Epoch [5/50], Step [200/600], Loss: 0.7479\n",
      "Epoch [5/50], Step [300/600], Loss: 0.7980\n",
      "Epoch [5/50], Step [400/600], Loss: 0.7739\n",
      "Epoch [5/50], Step [500/600], Loss: 0.7214\n",
      "Epoch [5/50], Step [600/600], Loss: 0.6756\n",
      "Epoch [6/50], Step [100/600], Loss: 0.6555\n",
      "Epoch [6/50], Step [200/600], Loss: 0.8393\n",
      "Epoch [6/50], Step [300/600], Loss: 0.8047\n",
      "Epoch [6/50], Step [400/600], Loss: 0.7132\n",
      "Epoch [6/50], Step [500/600], Loss: 0.7415\n",
      "Epoch [6/50], Step [600/600], Loss: 0.9167\n",
      "Epoch [7/50], Step [100/600], Loss: 0.6785\n",
      "Epoch [7/50], Step [200/600], Loss: 0.7275\n",
      "Epoch [7/50], Step [300/600], Loss: 0.7738\n",
      "Epoch [7/50], Step [400/600], Loss: 0.6902\n",
      "Epoch [7/50], Step [500/600], Loss: 0.6834\n",
      "Epoch [7/50], Step [600/600], Loss: 0.6110\n",
      "Epoch [8/50], Step [100/600], Loss: 0.6343\n",
      "Epoch [8/50], Step [200/600], Loss: 0.7997\n",
      "Epoch [8/50], Step [300/600], Loss: 0.6331\n",
      "Epoch [8/50], Step [400/600], Loss: 0.7159\n",
      "Epoch [8/50], Step [500/600], Loss: 0.8133\n",
      "Epoch [8/50], Step [600/600], Loss: 0.7511\n",
      "Epoch [9/50], Step [100/600], Loss: 0.7320\n",
      "Epoch [9/50], Step [200/600], Loss: 0.6062\n",
      "Epoch [9/50], Step [300/600], Loss: 0.7300\n",
      "Epoch [9/50], Step [400/600], Loss: 0.6599\n",
      "Epoch [9/50], Step [500/600], Loss: 0.6651\n",
      "Epoch [9/50], Step [600/600], Loss: 0.6253\n",
      "Epoch [10/50], Step [100/600], Loss: 0.7356\n",
      "Epoch [10/50], Step [200/600], Loss: 0.6173\n",
      "Epoch [10/50], Step [300/600], Loss: 0.7250\n",
      "Epoch [10/50], Step [400/600], Loss: 0.5797\n",
      "Epoch [10/50], Step [500/600], Loss: 0.5574\n",
      "Epoch [10/50], Step [600/600], Loss: 0.6064\n",
      "Epoch [11/50], Step [100/600], Loss: 0.7042\n",
      "Epoch [11/50], Step [200/600], Loss: 0.5670\n",
      "Epoch [11/50], Step [300/600], Loss: 0.6140\n",
      "Epoch [11/50], Step [400/600], Loss: 0.5547\n",
      "Epoch [11/50], Step [500/600], Loss: 0.6951\n",
      "Epoch [11/50], Step [600/600], Loss: 0.4611\n",
      "Epoch [12/50], Step [100/600], Loss: 0.6656\n",
      "Epoch [12/50], Step [200/600], Loss: 0.6203\n",
      "Epoch [12/50], Step [300/600], Loss: 0.5446\n",
      "Epoch [12/50], Step [400/600], Loss: 0.6113\n",
      "Epoch [12/50], Step [500/600], Loss: 0.6281\n",
      "Epoch [12/50], Step [600/600], Loss: 0.4987\n",
      "Epoch [13/50], Step [100/600], Loss: 0.5483\n",
      "Epoch [13/50], Step [200/600], Loss: 0.5376\n",
      "Epoch [13/50], Step [300/600], Loss: 0.6942\n",
      "Epoch [13/50], Step [400/600], Loss: 0.7305\n",
      "Epoch [13/50], Step [500/600], Loss: 0.6099\n",
      "Epoch [13/50], Step [600/600], Loss: 0.5969\n",
      "Epoch [14/50], Step [100/600], Loss: 0.5622\n",
      "Epoch [14/50], Step [200/600], Loss: 0.6606\n",
      "Epoch [14/50], Step [300/600], Loss: 0.5422\n",
      "Epoch [14/50], Step [400/600], Loss: 0.5393\n",
      "Epoch [14/50], Step [500/600], Loss: 0.5130\n",
      "Epoch [14/50], Step [600/600], Loss: 0.5061\n",
      "Epoch [15/50], Step [100/600], Loss: 0.4713\n",
      "Epoch [15/50], Step [200/600], Loss: 0.6813\n",
      "Epoch [15/50], Step [300/600], Loss: 0.5549\n",
      "Epoch [15/50], Step [400/600], Loss: 0.6665\n",
      "Epoch [15/50], Step [500/600], Loss: 0.5448\n",
      "Epoch [15/50], Step [600/600], Loss: 0.5912\n",
      "Epoch [16/50], Step [100/600], Loss: 0.5581\n",
      "Epoch [16/50], Step [200/600], Loss: 0.5204\n",
      "Epoch [16/50], Step [300/600], Loss: 0.6582\n",
      "Epoch [16/50], Step [400/600], Loss: 0.5408\n",
      "Epoch [16/50], Step [500/600], Loss: 0.5656\n",
      "Epoch [16/50], Step [600/600], Loss: 0.6059\n",
      "Epoch [17/50], Step [100/600], Loss: 0.5353\n",
      "Epoch [17/50], Step [200/600], Loss: 0.4944\n",
      "Epoch [17/50], Step [300/600], Loss: 0.4680\n",
      "Epoch [17/50], Step [400/600], Loss: 0.5905\n",
      "Epoch [17/50], Step [500/600], Loss: 0.4708\n",
      "Epoch [17/50], Step [600/600], Loss: 0.6199\n",
      "Epoch [18/50], Step [100/600], Loss: 0.6929\n",
      "Epoch [18/50], Step [200/600], Loss: 0.5097\n",
      "Epoch [18/50], Step [300/600], Loss: 0.4312\n",
      "Epoch [18/50], Step [400/600], Loss: 0.4702\n",
      "Epoch [18/50], Step [500/600], Loss: 0.6449\n",
      "Epoch [18/50], Step [600/600], Loss: 0.5134\n",
      "Epoch [19/50], Step [100/600], Loss: 0.5323\n",
      "Epoch [19/50], Step [200/600], Loss: 0.6291\n",
      "Epoch [19/50], Step [300/600], Loss: 0.5617\n",
      "Epoch [19/50], Step [400/600], Loss: 0.6427\n",
      "Epoch [19/50], Step [500/600], Loss: 0.4840\n",
      "Epoch [19/50], Step [600/600], Loss: 0.4437\n",
      "Epoch [20/50], Step [100/600], Loss: 0.6224\n",
      "Epoch [20/50], Step [200/600], Loss: 0.4638\n",
      "Epoch [20/50], Step [300/600], Loss: 0.6013\n",
      "Epoch [20/50], Step [400/600], Loss: 0.6590\n",
      "Epoch [20/50], Step [500/600], Loss: 0.3988\n",
      "Epoch [20/50], Step [600/600], Loss: 0.4332\n",
      "Epoch [21/50], Step [100/600], Loss: 0.4192\n",
      "Epoch [21/50], Step [200/600], Loss: 0.5010\n",
      "Epoch [21/50], Step [300/600], Loss: 0.5187\n",
      "Epoch [21/50], Step [400/600], Loss: 0.4974\n",
      "Epoch [21/50], Step [500/600], Loss: 0.6498\n",
      "Epoch [21/50], Step [600/600], Loss: 0.6182\n",
      "Epoch [22/50], Step [100/600], Loss: 0.5318\n",
      "Epoch [22/50], Step [200/600], Loss: 0.5001\n",
      "Epoch [22/50], Step [300/600], Loss: 0.4884\n",
      "Epoch [22/50], Step [400/600], Loss: 0.5003\n",
      "Epoch [22/50], Step [500/600], Loss: 0.4073\n",
      "Epoch [22/50], Step [600/600], Loss: 0.4508\n",
      "Epoch [23/50], Step [100/600], Loss: 0.4921\n",
      "Epoch [23/50], Step [200/600], Loss: 0.5127\n",
      "Epoch [23/50], Step [300/600], Loss: 0.5418\n",
      "Epoch [23/50], Step [400/600], Loss: 0.5020\n",
      "Epoch [23/50], Step [500/600], Loss: 0.4821\n",
      "Epoch [23/50], Step [600/600], Loss: 0.5092\n",
      "Epoch [24/50], Step [100/600], Loss: 0.4122\n",
      "Epoch [24/50], Step [200/600], Loss: 0.5152\n",
      "Epoch [24/50], Step [300/600], Loss: 0.4743\n",
      "Epoch [24/50], Step [400/600], Loss: 0.6336\n",
      "Epoch [24/50], Step [500/600], Loss: 0.5233\n",
      "Epoch [24/50], Step [600/600], Loss: 0.5181\n",
      "Epoch [25/50], Step [100/600], Loss: 0.4131\n",
      "Epoch [25/50], Step [200/600], Loss: 0.6067\n",
      "Epoch [25/50], Step [300/600], Loss: 0.5091\n",
      "Epoch [25/50], Step [400/600], Loss: 0.5944\n",
      "Epoch [25/50], Step [500/600], Loss: 0.4456\n",
      "Epoch [25/50], Step [600/600], Loss: 0.5158\n",
      "Epoch [26/50], Step [100/600], Loss: 0.4097\n",
      "Epoch [26/50], Step [200/600], Loss: 0.5363\n",
      "Epoch [26/50], Step [300/600], Loss: 0.5471\n",
      "Epoch [26/50], Step [400/600], Loss: 0.4895\n",
      "Epoch [26/50], Step [500/600], Loss: 0.4379\n",
      "Epoch [26/50], Step [600/600], Loss: 0.4631\n",
      "Epoch [27/50], Step [100/600], Loss: 0.4570\n",
      "Epoch [27/50], Step [200/600], Loss: 0.5304\n",
      "Epoch [27/50], Step [300/600], Loss: 0.5306\n",
      "Epoch [27/50], Step [400/600], Loss: 0.5013\n",
      "Epoch [27/50], Step [500/600], Loss: 0.4124\n",
      "Epoch [27/50], Step [600/600], Loss: 0.5399\n",
      "Epoch [28/50], Step [100/600], Loss: 0.3856\n",
      "Epoch [28/50], Step [200/600], Loss: 0.4754\n",
      "Epoch [28/50], Step [300/600], Loss: 0.3945\n",
      "Epoch [28/50], Step [400/600], Loss: 0.5458\n",
      "Epoch [28/50], Step [500/600], Loss: 0.5299\n",
      "Epoch [28/50], Step [600/600], Loss: 0.4303\n",
      "Epoch [29/50], Step [100/600], Loss: 0.5735\n",
      "Epoch [29/50], Step [200/600], Loss: 0.5488\n",
      "Epoch [29/50], Step [300/600], Loss: 0.6567\n",
      "Epoch [29/50], Step [400/600], Loss: 0.3658\n",
      "Epoch [29/50], Step [500/600], Loss: 0.5186\n",
      "Epoch [29/50], Step [600/600], Loss: 0.4571\n",
      "Epoch [30/50], Step [100/600], Loss: 0.4067\n",
      "Epoch [30/50], Step [200/600], Loss: 0.4864\n",
      "Epoch [30/50], Step [300/600], Loss: 0.4446\n",
      "Epoch [30/50], Step [400/600], Loss: 0.5520\n",
      "Epoch [30/50], Step [500/600], Loss: 0.4080\n",
      "Epoch [30/50], Step [600/600], Loss: 0.5253\n",
      "Epoch [31/50], Step [100/600], Loss: 0.4495\n",
      "Epoch [31/50], Step [200/600], Loss: 0.4651\n",
      "Epoch [31/50], Step [300/600], Loss: 0.3943\n",
      "Epoch [31/50], Step [400/600], Loss: 0.5174\n",
      "Epoch [31/50], Step [500/600], Loss: 0.4346\n",
      "Epoch [31/50], Step [600/600], Loss: 0.4782\n",
      "Epoch [32/50], Step [100/600], Loss: 0.4144\n",
      "Epoch [32/50], Step [200/600], Loss: 0.5957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [300/600], Loss: 0.4824\n",
      "Epoch [32/50], Step [400/600], Loss: 0.4016\n",
      "Epoch [32/50], Step [500/600], Loss: 0.4296\n",
      "Epoch [32/50], Step [600/600], Loss: 0.5153\n",
      "Epoch [33/50], Step [100/600], Loss: 0.5101\n",
      "Epoch [33/50], Step [200/600], Loss: 0.3951\n",
      "Epoch [33/50], Step [300/600], Loss: 0.4304\n",
      "Epoch [33/50], Step [400/600], Loss: 0.4307\n",
      "Epoch [33/50], Step [500/600], Loss: 0.4935\n",
      "Epoch [33/50], Step [600/600], Loss: 0.3778\n",
      "Epoch [34/50], Step [100/600], Loss: 0.4694\n",
      "Epoch [34/50], Step [200/600], Loss: 0.6972\n",
      "Epoch [34/50], Step [300/600], Loss: 0.5594\n",
      "Epoch [34/50], Step [400/600], Loss: 0.5194\n",
      "Epoch [34/50], Step [500/600], Loss: 0.4018\n",
      "Epoch [34/50], Step [600/600], Loss: 0.5449\n",
      "Epoch [35/50], Step [100/600], Loss: 0.4892\n",
      "Epoch [35/50], Step [200/600], Loss: 0.5412\n",
      "Epoch [35/50], Step [300/600], Loss: 0.4724\n",
      "Epoch [35/50], Step [400/600], Loss: 0.5298\n",
      "Epoch [35/50], Step [500/600], Loss: 0.5538\n",
      "Epoch [35/50], Step [600/600], Loss: 0.5467\n",
      "Epoch [36/50], Step [100/600], Loss: 0.5237\n",
      "Epoch [36/50], Step [200/600], Loss: 0.5226\n",
      "Epoch [36/50], Step [300/600], Loss: 0.5339\n",
      "Epoch [36/50], Step [400/600], Loss: 0.4676\n",
      "Epoch [36/50], Step [500/600], Loss: 0.4155\n",
      "Epoch [36/50], Step [600/600], Loss: 0.3803\n",
      "Epoch [37/50], Step [100/600], Loss: 0.3967\n",
      "Epoch [37/50], Step [200/600], Loss: 0.3391\n",
      "Epoch [37/50], Step [300/600], Loss: 0.5173\n",
      "Epoch [37/50], Step [400/600], Loss: 0.3973\n",
      "Epoch [37/50], Step [500/600], Loss: 0.5251\n",
      "Epoch [37/50], Step [600/600], Loss: 0.5097\n",
      "Epoch [38/50], Step [100/600], Loss: 0.4749\n",
      "Epoch [38/50], Step [200/600], Loss: 0.4227\n",
      "Epoch [38/50], Step [300/600], Loss: 0.3772\n",
      "Epoch [38/50], Step [400/600], Loss: 0.4077\n",
      "Epoch [38/50], Step [500/600], Loss: 0.4942\n",
      "Epoch [38/50], Step [600/600], Loss: 0.4453\n",
      "Epoch [39/50], Step [100/600], Loss: 0.4761\n",
      "Epoch [39/50], Step [200/600], Loss: 0.4532\n",
      "Epoch [39/50], Step [300/600], Loss: 0.4054\n",
      "Epoch [39/50], Step [400/600], Loss: 0.4511\n",
      "Epoch [39/50], Step [500/600], Loss: 0.3938\n",
      "Epoch [39/50], Step [600/600], Loss: 0.3409\n",
      "Epoch [40/50], Step [100/600], Loss: 0.4328\n",
      "Epoch [40/50], Step [200/600], Loss: 0.5761\n",
      "Epoch [40/50], Step [300/600], Loss: 0.4861\n",
      "Epoch [40/50], Step [400/600], Loss: 0.5768\n",
      "Epoch [40/50], Step [500/600], Loss: 0.4363\n",
      "Epoch [40/50], Step [600/600], Loss: 0.6684\n",
      "Epoch [41/50], Step [100/600], Loss: 0.3287\n",
      "Epoch [41/50], Step [200/600], Loss: 0.3774\n",
      "Epoch [41/50], Step [300/600], Loss: 0.3981\n",
      "Epoch [41/50], Step [400/600], Loss: 0.4762\n",
      "Epoch [41/50], Step [500/600], Loss: 0.6218\n",
      "Epoch [41/50], Step [600/600], Loss: 0.4910\n",
      "Epoch [42/50], Step [100/600], Loss: 0.4238\n",
      "Epoch [42/50], Step [200/600], Loss: 0.4670\n",
      "Epoch [42/50], Step [300/600], Loss: 0.3418\n",
      "Epoch [42/50], Step [400/600], Loss: 0.4457\n",
      "Epoch [42/50], Step [500/600], Loss: 0.3401\n",
      "Epoch [42/50], Step [600/600], Loss: 0.4075\n",
      "Epoch [43/50], Step [100/600], Loss: 0.4232\n",
      "Epoch [43/50], Step [200/600], Loss: 0.3990\n",
      "Epoch [43/50], Step [300/600], Loss: 0.3920\n",
      "Epoch [43/50], Step [400/600], Loss: 0.4291\n",
      "Epoch [43/50], Step [500/600], Loss: 0.4169\n",
      "Epoch [43/50], Step [600/600], Loss: 0.3577\n",
      "Epoch [44/50], Step [100/600], Loss: 0.3785\n",
      "Epoch [44/50], Step [200/600], Loss: 0.4157\n",
      "Epoch [44/50], Step [300/600], Loss: 0.5582\n",
      "Epoch [44/50], Step [400/600], Loss: 0.5358\n",
      "Epoch [44/50], Step [500/600], Loss: 0.4443\n",
      "Epoch [44/50], Step [600/600], Loss: 0.4350\n",
      "Epoch [45/50], Step [100/600], Loss: 0.4083\n",
      "Epoch [45/50], Step [200/600], Loss: 0.4385\n",
      "Epoch [45/50], Step [300/600], Loss: 0.4363\n",
      "Epoch [45/50], Step [400/600], Loss: 0.3775\n",
      "Epoch [45/50], Step [500/600], Loss: 0.5597\n",
      "Epoch [45/50], Step [600/600], Loss: 0.4659\n",
      "Epoch [46/50], Step [100/600], Loss: 0.4493\n",
      "Epoch [46/50], Step [200/600], Loss: 0.3809\n",
      "Epoch [46/50], Step [300/600], Loss: 0.4331\n",
      "Epoch [46/50], Step [400/600], Loss: 0.3667\n",
      "Epoch [46/50], Step [500/600], Loss: 0.5389\n",
      "Epoch [46/50], Step [600/600], Loss: 0.4530\n",
      "Epoch [47/50], Step [100/600], Loss: 0.3884\n",
      "Epoch [47/50], Step [200/600], Loss: 0.5060\n",
      "Epoch [47/50], Step [300/600], Loss: 0.5053\n",
      "Epoch [47/50], Step [400/600], Loss: 0.4456\n",
      "Epoch [47/50], Step [500/600], Loss: 0.4799\n",
      "Epoch [47/50], Step [600/600], Loss: 0.5407\n",
      "Epoch [48/50], Step [100/600], Loss: 0.3507\n",
      "Epoch [48/50], Step [200/600], Loss: 0.4357\n",
      "Epoch [48/50], Step [300/600], Loss: 0.5262\n",
      "Epoch [48/50], Step [400/600], Loss: 0.3191\n",
      "Epoch [48/50], Step [500/600], Loss: 0.4718\n",
      "Epoch [48/50], Step [600/600], Loss: 0.5512\n",
      "Epoch [49/50], Step [100/600], Loss: 0.4280\n",
      "Epoch [49/50], Step [200/600], Loss: 0.4911\n",
      "Epoch [49/50], Step [300/600], Loss: 0.4470\n",
      "Epoch [49/50], Step [400/600], Loss: 0.4012\n",
      "Epoch [49/50], Step [500/600], Loss: 0.5247\n",
      "Epoch [49/50], Step [600/600], Loss: 0.3034\n",
      "Epoch [50/50], Step [100/600], Loss: 0.3962\n",
      "Epoch [50/50], Step [200/600], Loss: 0.4793\n",
      "Epoch [50/50], Step [300/600], Loss: 0.4801\n",
      "Epoch [50/50], Step [400/600], Loss: 0.4629\n",
      "Epoch [50/50], Step [500/600], Loss: 0.4195\n",
      "Epoch [50/50], Step [600/600], Loss: 0.3165\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1,28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 11 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model \n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
